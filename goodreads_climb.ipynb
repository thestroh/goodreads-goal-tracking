{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a kid, I read all the time. Then, when it became a more academic endeavor, I somehow fell out of love with reading for fun. Last year I was determined to change that, and so I bought the books that came most highly recommended by my friends and started a new journey. In an effort to keep motivated, I documented what I read on Goodreads. \n",
    "\n",
    "When 2024 started, Goodreads prompted me to set a reading goal which felt like a fun way to motivate myself to read even more, but they don't really promote that goal in any interesting way. So I thought I'd do that for myself, by tracking my reading journey and displaying it in a more interesting way. \n",
    "\n",
    "So the goal is simple: Get the books I've read, calculate the approximate amount of words contained in those books, and then visualize the distance those words span. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I need to get the list of books I've read in the current year from my Goodreads account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def get_reading_list(user_id, year = \"2024\"):\n",
    "    \"\"\"\n",
    "    Obtains a list of all books read in the specified year by the specified user from their Goodreads profile.\n",
    "    @param user_id: The user_id, in numeric form, for the Goodreads account.\n",
    "    @param year: The year to obtain the reading list for.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.goodreads.com/review/list/{user_id}?date_added={year}\"\n",
    "\n",
    "    standard_headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "    try:\n",
    "        r = requests.get(url, headers=standard_headers)\n",
    "        r.raise_for_status()  # Raises HTTPError for bad status codes\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"Error: {err.response.status_code}\")\n",
    "        time.sleep(5)\n",
    "        return None\n",
    "    \n",
    "    # Parse the HTML and find the correct table rows to loop through for the correct data\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    books_table = soup.find(\"table\", {\"id\": \"books\"}).find(\"tbody\").find_all(\"tr\")\n",
    "    books_read = {}\n",
    "\n",
    "    for book in books_table:\n",
    "        item = book.find(\"td\", {\"class\":\"field title\"}).find(\"div\").find(\"a\")\n",
    "        # Cleaning the title of whitespace at the ends, new lines, and then white space between title & sub-title\n",
    "        title = \" \".join(item.text.strip().replace('\\n',' ').split())\n",
    "        link = item.get(\"href\")\n",
    "\n",
    "        books_read[title] = link\n",
    "\n",
    "    return books_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"15147556\"\n",
    "books_read = get_reading_list(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The Kind Worth Killing (Henry Kimball/Lily Kintner, #1)': '/book/show/21936809-the-kind-worth-killing', 'Book Lovers': '/book/show/58690308-book-lovers', 'The Invisible Life of Addie LaRue': '/book/show/50623864-the-invisible-life-of-addie-larue', 'Project Hail Mary': '/book/show/54493401-project-hail-mary', 'Hell Bent (Alex Stern, #2)': '/book/show/60652997-hell-bent', 'Ninth House (Alex Stern, #1)': '/book/show/43263680-ninth-house', 'The Sword of Kaigen': '/book/show/41886271-the-sword-of-kaigen', 'The Fires of Vengeance (The Burning, #2)': '/book/show/43174603-the-fires-of-vengeance', 'The Light of All That Falls (The Licanius Trilogy, #3)': '/book/show/36111098-the-light-of-all-that-falls', 'An Echo of Things to Come (The Licanius Trilogy, #2)': '/book/show/32498052-an-echo-of-things-to-come', 'The Rage of Dragons (The Burning, #1)': '/book/show/41952489-the-rage-of-dragons', 'The Shadow of What Was Lost (The Licanius Trilogy, #1)': '/book/show/22878967-the-shadow-of-what-was-lost', 'Yellowface': '/book/show/62047984-yellowface', 'The City We Became (Great Cities, #1)': '/book/show/42074525-the-city-we-became', 'House of Salt and Sorrows (Sisters of the Salt, #1)': '/book/show/39679076-house-of-salt-and-sorrows', 'Beartown (Beartown, #1)': '/book/show/33413128-beartown', 'The Final Gambit (The Inheritance Games, #3)': '/book/show/58658940-the-final-gambit', 'The Hawthorne Legacy (The Inheritance Games, #2)': '/book/show/50531218-the-hawthorne-legacy', 'The Glass Hotel': '/book/show/45754981-the-glass-hotel', 'The Will of the Many (Hierarchy, #1)': '/book/show/58416952-the-will-of-the-many'}\n"
     ]
    }
   ],
   "source": [
    "print(books_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a dictionary containing the name of each book from my reading list, and the link Goodreads provided to that book's page.\n",
    "Next, we can use those links to get book-level details such as the number of pages (unfortunately, word counts don't seem to be a provided data point, so that'll have to be extrapolated based on industry averages per page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_book_details(book_url):\n",
    "    \"\"\"\n",
    "    Separate function for obtaining book details (page count) from Goodreads.\n",
    "    Makes two total attempts before erroring and returning None. Second attempt is delayed 5 seconds in case of limits.\n",
    "    @param book_url: URL for the Goodreads book page.\n",
    "    \"\"\"\n",
    "    standard_headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "\n",
    "    try:\n",
    "        r = requests.get(book_url, headers=standard_headers)\n",
    "        r.raise_for_status()  # Raises HTTPError for bad status codes\n",
    "        return r.text\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"Error: {err.response.status_code}\")\n",
    "        time.sleep(5)\n",
    "        return None  # Returning None to indicate failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_data(dict):\n",
    "    \"\"\"\n",
    "    Obtains the details (page count) for books on Goodreads and compiles the total books and total pages from the dict.\n",
    "    @param dict: A dictionary containing book names and links to lookup data for.\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.goodreads.com\"\n",
    "\n",
    "    # Setup data structures for book processing\n",
    "    book_data = []\n",
    "    total_books = 0\n",
    "    total_pages = 0\n",
    "\n",
    "    # Construct book_url\n",
    "    for book, link in dict.items():\n",
    "        book_url = base_url + link\n",
    "        retries = 2 # Number of attempts to make before erroring out\n",
    "\n",
    "        while retries > 0:\n",
    "            book_details = fetch_book_details(book_url)\n",
    "            #time.sleep(1)\n",
    "            if book_data is not None:\n",
    "                soup = BeautifulSoup(book_details, 'html.parser')\n",
    "                 # Grab pages (just the initial number)\n",
    "                pages = int(soup.find(\"p\", {\"data-testid\": \"pagesFormat\"}).text.split(\" \")[0])\n",
    "                # List comprehension to get a list of all genres book is tagged with\n",
    "                genres = [span.find(\"a\").find(\"span\").text for span in soup.find_all(\"span\", {\"class\": \"BookPageMetadataSection__genreButton\"})]\n",
    "                # Construct a temp dictionary\n",
    "                temp_dict = {\n",
    "                    \"name\": book,\n",
    "                    \"pages\": pages,\n",
    "                    \"genres\": genres\n",
    "                }\n",
    "                # Append temp dictionary to our list to add to the final dict\n",
    "                book_data.append(temp_dict)\n",
    "                # Since we're already looping through all books here, might as well keep track for overall variables\n",
    "                total_books += 1\n",
    "                total_pages += pages\n",
    "                break\n",
    "            else:\n",
    "                retries -= 1\n",
    "                if retries == 0:\n",
    "                    print(f\"Encountered multiple errors querying book data for {book}\")\n",
    "    \n",
    "    data_output = {\n",
    "        \"book_count\": total_books,\n",
    "        \"total_pages\": total_pages,\n",
    "        \"books\": book_data\n",
    "    }\n",
    "\n",
    "    return data_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just for simplicity, I'll create a final function that just wraps all of these scraping functions into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all(user_id, year = \"2024\"):\n",
    "    \"\"\"\n",
    "    Composite operation, fetching the user's book list for the specified year and then calculating the book data for \n",
    "    every book on that list. Returns a json-like dictionary containing total books, total pages, and book details.\n",
    "    @param user_id: The user_id, in numeric form, for the Goodreads account.\n",
    "    @param year: The year to obtain the reading list for.\n",
    "    \"\"\"\n",
    "    # First, get all books for reading list\n",
    "    books_read = get_reading_list(user_id, year)\n",
    "    # Next, calculate book data.\n",
    "    books_data = get_book_data(books_read)\n",
    "    return books_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'book_count': 20, 'total_pages': 9830, 'books': [{'name': 'The Kind Worth Killing (Henry Kimball/Lily Kintner, #1)', 'pages': 320, 'genres': ['Thriller', 'Mystery', 'Fiction', 'Mystery Thriller', 'Crime', 'Audiobook', 'Suspense']}, {'name': 'Book Lovers', 'pages': 377, 'genres': ['Romance', 'Fiction', 'Contemporary', 'Audiobook', 'Contemporary Romance', 'Adult', 'Chick Lit']}, {'name': 'The Invisible Life of Addie LaRue', 'pages': 448, 'genres': ['Fantasy', 'Fiction', 'Romance', 'Historical Fiction', 'Adult', 'Historical', 'Magical Realism']}, {'name': 'Project Hail Mary', 'pages': 476, 'genres': ['Science Fiction', 'Fiction', 'Audiobook', 'Fantasy', 'Space', 'Adult', 'Thriller']}, {'name': 'Hell Bent (Alex Stern, #2)', 'pages': 481, 'genres': ['Fantasy', 'Fiction', 'Horror', 'Mystery', 'Urban Fantasy', 'Paranormal', 'Adult']}, {'name': 'Ninth House (Alex Stern, #1)', 'pages': 461, 'genres': ['Fantasy', 'Mystery', 'Fiction', 'Horror', 'Paranormal', 'Adult', 'Urban Fantasy']}, {'name': 'The Sword of Kaigen', 'pages': 651, 'genres': ['Fantasy', 'Fiction', 'Adult', 'High Fantasy', 'Epic Fantasy', 'Magic', 'Science Fiction Fantasy']}, {'name': 'The Fires of Vengeance (The Burning, #2)', 'pages': 529, 'genres': ['Fantasy', 'Fiction', 'Dragons', 'Epic Fantasy', 'Adult', 'High Fantasy', 'Audiobook']}, {'name': 'The Light of All That Falls (The Licanius Trilogy, #3)', 'pages': 864, 'genres': ['Fantasy', 'Fiction', 'Epic Fantasy', 'High Fantasy', 'Audiobook', 'Adult', 'Magic']}, {'name': 'An Echo of Things to Come (The Licanius Trilogy, #2)', 'pages': 752, 'genres': ['Fantasy', 'Fiction', 'Epic Fantasy', 'High Fantasy', 'Audiobook', 'Adult', 'Magic']}, {'name': 'The Rage of Dragons (The Burning, #1)', 'pages': 535, 'genres': ['Fantasy', 'Dragons', 'Fiction', 'Adult', 'High Fantasy', 'Epic Fantasy', 'Audiobook']}, {'name': 'The Shadow of What Was Lost (The Licanius Trilogy, #1)', 'pages': 602, 'genres': ['Fantasy', 'Fiction', 'Epic Fantasy', 'High Fantasy', 'Adult', 'Magic', 'Audiobook']}, {'name': 'Yellowface', 'pages': 336, 'genres': ['Fiction', 'Contemporary', 'Audiobook', 'Literary Fiction', 'Thriller', 'Adult', 'Mystery']}, {'name': 'The City We Became (Great Cities, #1)', 'pages': 437, 'genres': ['Fantasy', 'Fiction', 'Science Fiction', 'Urban Fantasy', 'Audiobook', 'Adult', 'LGBT']}, {'name': 'House of Salt and Sorrows (Sisters of the Salt, #1)', 'pages': 403, 'genres': ['Fantasy', 'Young Adult', 'Retellings', 'Horror', 'Mystery', 'Romance', 'Fiction']}, {'name': 'Beartown (Beartown, #1)', 'pages': 432, 'genres': ['Fiction', 'Contemporary', 'Audiobook', 'Sports', 'Adult', 'Literary Fiction', 'Adult Fiction']}, {'name': 'The Final Gambit (The Inheritance Games, #3)', 'pages': 400, 'genres': ['Mystery', 'Young Adult', 'Romance', 'Fiction', 'Mystery Thriller', 'Contemporary', 'Thriller']}, {'name': 'The Hawthorne Legacy (The Inheritance Games, #2)', 'pages': 380, 'genres': ['Mystery', 'Young Adult', 'Romance', 'Fiction', 'Mystery Thriller', 'Contemporary', 'Thriller']}, {'name': 'The Glass Hotel', 'pages': 307, 'genres': ['Fiction', 'Contemporary', 'Mystery', 'Literary Fiction', 'Audiobook', 'Adult', 'Canada']}, {'name': 'The Will of the Many (Hierarchy, #1)', 'pages': 639, 'genres': ['Fantasy', 'Fiction', 'Mystery', 'High Fantasy', 'Adult', 'Science Fiction', 'Epic Fantasy']}]}\n"
     ]
    }
   ],
   "source": [
    "books_data = fetch_all(user_id)\n",
    "print(books_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes a bit to run, and there's some built-in reattempts and slowdowns because Goodreads can be a bit fickle when scraping, but overall it's not very long and it only needs to run that one time to get our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the visualization, I wanted something that works well within the realm of books that most people will read. The initial idea was to draw a distance on a map of the United States, but for people who only read a handful of books in a year, it would be an inconsequential mark. Even for those who read a lot, they wouldn't come close to crossing the entire map.\n",
    "\n",
    "So the next idea that matched my desired parameters, and also gave a scope that was encouraging, was Mount Everest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhat surprisingly to me, Mount Everest may have a tall reputation, but compared to horizontal distances we deal with daily it's actually pretty manageable (obviously the difficulty doesn't come from pure hike length). Additionally, if we start from the Base Camp, that cuts out a good chunk. \n",
    "\n",
    "What if someone reads a ton though? Well, we can convert the data visualization to show a more realistic hike then complete with acclimatization steps (essentially going up, then coming back down repeatedly to get used to elevation changes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"test1.png\"/ width=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found this image online and modified it slightly - and will probalby modify it more for the final product - but for now it's a good starting point. I'm combining this with hiking distance data I found at https://www.alanarnette.com/everest/everestsouthroutes.php\n",
    "\n",
    "That data is as follows:\n",
    "* Base Camp to Icefall: He doesn't actually say.\n",
    "* Icefall to Camp I: 1.62 miles\n",
    "* Camp I to Camp II: 1.74 miles\n",
    "* Camp II to Camp III: 1.64 miles\n",
    "* Camp III to Camp IV: 0.8 miles\n",
    "* Camp IV to Summit: 1.07 miles\n",
    "\n",
    "The main issue is that he doesn't explicitly state a distance between Base Camp and the Icefall. Looking at lots of photos, it seems like the technical start of Khumbu Icefall on this Southern path is super close to Base Camp, so I think I can fairly safely assume the 1.62 miles stated from Icefall to Camp I is valid to use for the entire Base Camp to Camp I segment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the author provides a Youtube video outlining their actual path taken, which is as follows:\n",
    "1. Base to Icefall \n",
    "2. Icefall back to Base\n",
    "3. Base to C1 \n",
    "4. C1 back to Base\n",
    "5. Base to C2, \n",
    "6. C2 back to Base\n",
    "7. Base to C2\n",
    "8. C2 to C3\n",
    "9. C3 back to C2\n",
    "10. C2 back to Base\n",
    "11. Base to C2\n",
    "12. C2 to C3\n",
    "13. C3 to C4\n",
    "14. C4 to Summit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that's enough data theorizing for now. Next step is to convert the actual path on the image to a distance. Then, when the distance from the reading list is calculated, it can be converted to a spot on the trail (simplifying things and assuming linear distance on the image).\n",
    "\n",
    "First, I'll remove the extraneous red circles just to make things easier to analyze using CV2.\n",
    "\n",
    "<div>\n",
    "<img src=\"test2.png\"/ width=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (404, 747), 2: (408, 744), 3: (413, 741), 4: (418, 738), 5: (422, 736), 6: (428, 735), 7: (432, 732), 8: (428, 728), 9: (425, 724), 10: (421, 720), 11: (417, 717), 12: (413, 712), 13: (410, 708), 14: (409, 703), 15: (411, 699), 16: (416, 696), 17: (427, 695), 18: (421, 695), 19: (443, 694), 20: (438, 694), 21: (432, 694), 22: (448, 693), 23: (454, 692), 24: (465, 691), 25: (470, 690), 26: (481, 689), 27: (486, 688), 28: (502, 686), 29: (497, 686), 30: (507, 685), 31: (513, 683), 32: (518, 682), 33: (523, 680), 34: (528, 677), 35: (532, 673), 36: (535, 669), 37: (535, 664), 38: (533, 659), 39: (529, 654), 40: (525, 651), 41: (521, 647), 42: (517, 644), 43: (513, 640), 44: (509, 637), 45: (505, 634), 46: (500, 630), 47: (497, 627), 48: (496, 621), 49: (500, 618), 50: (505, 615), 51: (510, 614), 52: (515, 613), 53: (520, 612), 54: (526, 611), 55: (531, 609), 56: (536, 608), 57: (541, 606), 58: (546, 604), 59: (551, 601), 60: (556, 599), 61: (561, 596), 62: (566, 595), 63: (601, 582), 64: (606, 579), 65: (609, 574), 66: (612, 570), 67: (614, 565), 68: (615, 560), 69: (613, 555), 70: (610, 550), 71: (606, 547), 72: (602, 543), 73: (598, 539), 74: (594, 535), 75: (590, 532), 76: (587, 528), 77: (583, 524), 78: (579, 520), 79: (575, 516), 80: (571, 513), 81: (567, 509), 82: (563, 505), 83: (551, 487), 84: (549, 482), 85: (546, 478), 86: (541, 468), 87: (538, 464), 88: (536, 459), 89: (535, 454), 90: (536, 443), 91: (539, 439), 92: (542, 435), 93: (546, 431), 94: (550, 428), 95: (554, 423), 96: (557, 418), 97: (560, 414), 98: (564, 410), 99: (568, 407), 100: (571, 402), 101: (568, 398), 102: (564, 395), 103: (560, 391), 104: (556, 388), 105: (551, 385), 106: (543, 379), 107: (537, 377), 108: (532, 375), 109: (527, 373), 110: (504, 359), 111: (491, 349), 112: (486, 347), 113: (482, 344), 114: (478, 340), 115: (474, 336), 116: (472, 331), 117: (472, 326), 118: (473, 321), 119: (475, 316), 120: (476, 310), 121: (477, 305), 122: (476, 299), 123: (475, 294), 124: (474, 289), 125: (472, 284), 126: (470, 279), 127: (467, 274), 128: (464, 269), 129: (461, 265), 130: (458, 261), 131: (454, 257), 132: (451, 253), 133: (448, 248), 134: (445, 243), 135: (442, 239), 136: (438, 235), 137: (434, 231), 138: (431, 227), 139: (427, 223), 140: (424, 219), 141: (420, 215), 142: (416, 211), 143: (412, 208), 144: (407, 205), 145: (403, 201), 146: (380, 188), 147: (375, 186), 148: (369, 185), 149: (364, 184), 150: (360, 182), 151: (356, 177), 152: (353, 173), 153: (350, 168), 154: (347, 164), 155: (344, 159), 156: (341, 155), 157: (338, 150), 158: (335, 146), 159: (331, 142), 160: (328, 137), 161: (325, 134), 162: (321, 129), 163: (317, 125), 164: (314, 121), 165: (310, 117), 166: (307, 112), 167: (304, 108), 168: (300, 104), 169: (297, 100), 170: (293, 96), 171: (290, 92), 172: (287, 87), 173: (283, 83), 174: (280, 79), 175: (277, 74), 176: (273, 71), 177: (270, 67), 178: (266, 63), 179: (262, 58), 180: (257, 58), 181: (251, 58), 182: (247, 57), 183: (243, 53), 184: (239, 50), 185: (234, 47), 186: (230, 44)}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('test2.png')\n",
    "\n",
    "# Threshold the image to isolate the trail\n",
    "lower_red = np.array([0, 0, 150])\n",
    "upper_red = np.array([145, 145, 255]) # Modify this to get the correct threshold for just the trail\n",
    "mask = cv2.inRange(image, lower_red, upper_red)\n",
    "\n",
    "# Can uncomment this to see the mask and verify the upper_red threshold is set correct\n",
    "# cv2.imshow('Thresholded Image', mask)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# Find contours in the thresholded image\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create a dictionary to store the coordinates of the red dots that make up the trail\n",
    "red_dots = {}\n",
    "\n",
    "for i, contour in enumerate(contours):\n",
    "    # Initially tried using Moments, but some of the red dots for the trail marking are too small\n",
    "    # and so Moments was having issues detecting a center. Instead, can just calculate that manually.\n",
    "\n",
    "    # Calculate the area of the contour\n",
    "    area = cv2.contourArea(contour)\n",
    "    if area < 0.1:\n",
    "        # Assign a predefined small area value\n",
    "        area = 0.1\n",
    "    \n",
    "    # For each contour, sum x and y values and divide by total count to get average x/y position as center\n",
    "    sum_x = 0\n",
    "    sum_y = 0\n",
    "    count = 0\n",
    "\n",
    "    for point in contour:\n",
    "        x, y = point[0]\n",
    "        sum_x += x\n",
    "        sum_y += y\n",
    "        count += 1\n",
    "\n",
    "    if count != 0:\n",
    "        cX = int(sum_x / count)\n",
    "        cY = int(sum_y / count)\n",
    "        red_dots[i + 1] = (cX, cY)\n",
    "\n",
    "print(red_dots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can easily be checked just by opening the image in Paint and verifying the (x,y) coordinates of the red dots after zooming in. Everything looks good. \n",
    "\n",
    "The next step is to get the euclidean distance between these (x,y) coordinates. This will give the sum total distance for the entire path going from point-to-point for conversion into mileage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_distance(point1, point2):\n",
    "    # Simple function to calculate euclidean distance\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    return round(math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [(404, 747), 0], 2: [(408, 744), 5.0], 3: [(413, 741), 5.83], 4: [(418, 738), 5.83], 5: [(422, 736), 4.47], 6: [(428, 735), 6.08], 7: [(432, 732), 5.0], 8: [(428, 728), 5.66], 9: [(425, 724), 5.0], 10: [(421, 720), 5.66], 11: [(417, 717), 5.0], 12: [(413, 712), 6.4], 13: [(410, 708), 5.0], 14: [(409, 703), 5.1], 15: [(411, 699), 4.47], 16: [(416, 696), 5.83], 17: [(427, 695), 11.05], 18: [(421, 695), 6.0], 19: [(443, 694), 22.02], 20: [(438, 694), 5.0], 21: [(432, 694), 6.0], 22: [(448, 693), 16.03], 23: [(454, 692), 6.08], 24: [(465, 691), 11.05], 25: [(470, 690), 5.1], 26: [(481, 689), 11.05], 27: [(486, 688), 5.1], 28: [(502, 686), 16.12], 29: [(497, 686), 5.0], 30: [(507, 685), 10.05], 31: [(513, 683), 6.32], 32: [(518, 682), 5.1], 33: [(523, 680), 5.39], 34: [(528, 677), 5.83], 35: [(532, 673), 5.66], 36: [(535, 669), 5.0], 37: [(535, 664), 5.0], 38: [(533, 659), 5.39], 39: [(529, 654), 6.4], 40: [(525, 651), 5.0], 41: [(521, 647), 5.66], 42: [(517, 644), 5.0], 43: [(513, 640), 5.66], 44: [(509, 637), 5.0], 45: [(505, 634), 5.0], 46: [(500, 630), 6.4], 47: [(497, 627), 4.24], 48: [(496, 621), 6.08], 49: [(500, 618), 5.0], 50: [(505, 615), 5.83], 51: [(510, 614), 5.1], 52: [(515, 613), 5.1], 53: [(520, 612), 5.1], 54: [(526, 611), 6.08], 55: [(531, 609), 5.39], 56: [(536, 608), 5.1], 57: [(541, 606), 5.39], 58: [(546, 604), 5.39], 59: [(551, 601), 5.83], 60: [(556, 599), 5.39], 61: [(561, 596), 5.83], 62: [(566, 595), 5.1], 63: [(601, 582), 37.34], 64: [(606, 579), 5.83], 65: [(609, 574), 5.83], 66: [(612, 570), 5.0], 67: [(614, 565), 5.39], 68: [(615, 560), 5.1], 69: [(613, 555), 5.39], 70: [(610, 550), 5.83], 71: [(606, 547), 5.0], 72: [(602, 543), 5.66], 73: [(598, 539), 5.66], 74: [(594, 535), 5.66], 75: [(590, 532), 5.0], 76: [(587, 528), 5.0], 77: [(583, 524), 5.66], 78: [(579, 520), 5.66], 79: [(575, 516), 5.66], 80: [(571, 513), 5.0], 81: [(567, 509), 5.66], 82: [(563, 505), 5.66], 83: [(551, 487), 21.63], 84: [(549, 482), 5.39], 85: [(546, 478), 5.0], 86: [(541, 468), 11.18], 87: [(538, 464), 5.0], 88: [(536, 459), 5.39], 89: [(535, 454), 5.1], 90: [(536, 443), 11.05], 91: [(539, 439), 5.0], 92: [(542, 435), 5.0], 93: [(546, 431), 5.66], 94: [(550, 428), 5.0], 95: [(554, 423), 6.4], 96: [(557, 418), 5.83], 97: [(560, 414), 5.0], 98: [(564, 410), 5.66], 99: [(568, 407), 5.0], 100: [(571, 402), 5.83], 101: [(568, 398), 5.0], 102: [(564, 395), 5.0], 103: [(560, 391), 5.66], 104: [(556, 388), 5.0], 105: [(551, 385), 5.83], 106: [(543, 379), 10.0], 107: [(537, 377), 6.32], 108: [(532, 375), 5.39], 109: [(527, 373), 5.39], 110: [(504, 359), 26.93], 111: [(491, 349), 16.4], 112: [(486, 347), 5.39], 113: [(482, 344), 5.0], 114: [(478, 340), 5.66], 115: [(474, 336), 5.66], 116: [(472, 331), 5.39], 117: [(472, 326), 5.0], 118: [(473, 321), 5.1], 119: [(475, 316), 5.39], 120: [(476, 310), 6.08], 121: [(477, 305), 5.1], 122: [(476, 299), 6.08], 123: [(475, 294), 5.1], 124: [(474, 289), 5.1], 125: [(472, 284), 5.39], 126: [(470, 279), 5.39], 127: [(467, 274), 5.83], 128: [(464, 269), 5.83], 129: [(461, 265), 5.0], 130: [(458, 261), 5.0], 131: [(454, 257), 5.66], 132: [(451, 253), 5.0], 133: [(448, 248), 5.83], 134: [(445, 243), 5.83], 135: [(442, 239), 5.0], 136: [(438, 235), 5.66], 137: [(434, 231), 5.66], 138: [(431, 227), 5.0], 139: [(427, 223), 5.66], 140: [(424, 219), 5.0], 141: [(420, 215), 5.66], 142: [(416, 211), 5.66], 143: [(412, 208), 5.0], 144: [(407, 205), 5.83], 145: [(403, 201), 5.66], 146: [(380, 188), 26.42], 147: [(375, 186), 5.39], 148: [(369, 185), 6.08], 149: [(364, 184), 5.1], 150: [(360, 182), 4.47], 151: [(356, 177), 6.4], 152: [(353, 173), 5.0], 153: [(350, 168), 5.83], 154: [(347, 164), 5.0], 155: [(344, 159), 5.83], 156: [(341, 155), 5.0], 157: [(338, 150), 5.83], 158: [(335, 146), 5.0], 159: [(331, 142), 5.66], 160: [(328, 137), 5.83], 161: [(325, 134), 4.24], 162: [(321, 129), 6.4], 163: [(317, 125), 5.66], 164: [(314, 121), 5.0], 165: [(310, 117), 5.66], 166: [(307, 112), 5.83], 167: [(304, 108), 5.0], 168: [(300, 104), 5.66], 169: [(297, 100), 5.0], 170: [(293, 96), 5.66], 171: [(290, 92), 5.0], 172: [(287, 87), 5.83], 173: [(283, 83), 5.66], 174: [(280, 79), 5.0], 175: [(277, 74), 5.83], 176: [(273, 71), 5.0], 177: [(270, 67), 5.0], 178: [(266, 63), 5.66], 179: [(262, 58), 6.4], 180: [(257, 58), 5.0], 181: [(251, 58), 6.0], 182: [(247, 57), 4.12], 183: [(243, 53), 5.66], 184: [(239, 50), 5.0], 185: [(234, 47), 5.83], 186: [(230, 44), 5.0]}\n",
      "1179.31\n"
     ]
    }
   ],
   "source": [
    "# First point will be set to 0 unless I want to change it to the base camp duration later on, so this exempts it\n",
    "previous_point = None\n",
    "\n",
    "# Creating a new dict to modify\n",
    "trail = dict(red_dots)\n",
    "\n",
    "for key, coordinates in trail.items():\n",
    "    if previous_point is not None:\n",
    "        distance = calculate_distance(previous_point, coordinates)\n",
    "        trail[key] = [coordinates, distance]\n",
    "    else:\n",
    "        trail[key] = [coordinates, 0]\n",
    "    previous_point = coordinates\n",
    "\n",
    "# Calculating the total trail distance\n",
    "total_distance = 0\n",
    "for data in trail.values():\n",
    "    _, distance = data\n",
    "    total_distance += distance\n",
    "\n",
    "print(trail)\n",
    "print(round(total_distance,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with the total distance, that can now be mapped to the mileage of our hike from before. Therefore\n",
    "\n",
    "1179.31 units = (1.62 + 1.74 + 1.64 + 0.8 + 1.07 miles) = 6.87 miles\n",
    "\n",
    "So, if our calculated reading length was 3.1 miles, it's as simple as doing the following calculation:\n",
    "\n",
    "(3.1 / 6.87) * 1179.31 = 532.15 units hiked\n",
    "\n",
    "Then we can just loop through the trail until we've hiked 532.15 units, and that will be how far we've read to. We could go one point prior, or find the average distance between the point before 532.15 units and the point after that is the correct distance, but I think that's a level of specificity that's unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: (551, 487)\n"
     ]
    }
   ],
   "source": [
    "target_distance = 535.15\n",
    "accumulated_distance = 0\n",
    "target_coordinates = None\n",
    "\n",
    "for key, data in trail.items():\n",
    "    coordinates, distance = data\n",
    "    accumulated_distance += distance\n",
    "    if accumulated_distance >= target_distance:\n",
    "        target_coordinates = coordinates\n",
    "        break\n",
    "\n",
    "print(f\"Target: {target_coordinates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quickly verify, since this should be just below 50% of the way up the trail, we can draw a dot there to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "image = Image.open(\"test2.png\")\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "x,y = target_coordinates\n",
    "left = x-5\n",
    "top = y-5\n",
    "right = x+5\n",
    "bottom = y+5\n",
    "\n",
    "draw.rectangle([left, top, right, bottom], fill = \"red\")\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a bit hard to tell if that's close to 50% of the way, but it looks fairly correct since the start contains much more twists in the trail than the latter part of the hike where it's mostly straightforward vertical climbing. \n",
    "\n",
    "Ok, now we just need a quick calculation for the total distance from our book data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9830\n"
     ]
    }
   ],
   "source": [
    "print(books_data['total_pages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The industry standard for words per page seems to be ~300. I tested with a few random books from my shelf and this definitely seemed accurate for paperbacks, but a bit low for larger hardcovers. However, Goodreads data seems to tend towards a larger number of pages (for *The Will of the Many* it was +25 pages compared to my hardcover) since it commonly uses Kindle editions.\n",
    "\n",
    "Even for my paperback copy of *The Stone Sky*, which is the edition Goodreads supposedly uses, it was +20 pages off, possibly due to counting appendecies and such or perhaps it's just a different paperback print format. \n",
    "\n",
    "Since 300 words/page seems like it'll be a slight underestimation (my random page count for *The Stone Sky* was 284, and for *The Will of the Many* was a whopping 500), I think it'll end up working nicely in conjunction with Goodreads' inflated values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, 300 words/page. In English, the average word length is 4.7 characters. Both books I've been using for physical data have a 5-letter word come out to almost exactly 1/4 of an inch. That means the average word, at 4.7 characters, would be ~0.235 inches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.937736742424242\n"
     ]
    }
   ],
   "source": [
    "def get_reading_distance(total_pages, wpp = 300, ipw = 0.235):\n",
    "    \"\"\"\n",
    "    Returns the reading distance for a total number of pages as a mileage.\n",
    "    @param total_pages: A numeric value of the total number of pages.\n",
    "    @param wpp: The average words per page, default is 300.\n",
    "    @param ipw: The average inches per word, default is 0.235.\n",
    "    \"\"\"\n",
    "    # 12 inches/ft, 5280 ft/mile, 63360 inches/mile\n",
    "    books_distance = (total_pages * wpp * ipw) / 63360\n",
    "    return books_distance\n",
    "\n",
    "books_distance = get_reading_distance(books_data['total_pages'])\n",
    "print(books_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So my 2024 reading list is already more than the distance, so I would have either completed my journey or I could choose the actual climbing route which loops back to the base camp after hitting certain elevations. No matter, because we can make both an option. \n",
    "\n",
    "Might as well check the data for my 2023 reading list which may be shorter as another testing point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.812807765151515\n"
     ]
    }
   ],
   "source": [
    "test_2023_reading = fetch_all(user_id, \"2023\")\n",
    "test_2023_distance = get_reading_distance(test_2023_reading['total_pages'])\n",
    "print(test_2023_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_trail(trail, camp_index):\n",
    "    # Draw a line on the trail up until a specified index\n",
    "    image = Image.open('everest_template_clean.png')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    color = \"blue\"\n",
    "    thickness = 5\n",
    "\n",
    "    for i in range(1, camp_index + 1):\n",
    "        if i in trail:\n",
    "            x, y = trail[i][0]\n",
    "            if i > 1:\n",
    "                prev_x, prev_y = trail[i - 1][0]\n",
    "                draw.line([(prev_x, prev_y), (x, y)], fill = color, width = thickness, joint = 'curve')\n",
    "\n",
    "    image.save('everest_reading_journey.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_data(distance, acclimatization = False):\n",
    "    \"\"\"\n",
    "    Returns a string based on the distance provided explaining the percentage of the journey completed, as well as what \n",
    "    major landmarks have been passed. \n",
    "    \"\"\"\n",
    "\n",
    "    distance = round(distance, 2)\n",
    "    if acclimatization:\n",
    "        percent_hiked = round((distance / 30.07) * 100, 2)\n",
    "        label = [f\"Congratulations, you have read for a total of {distance} miles, \",\n",
    "                  f\"which is {percent_hiked}% of the total journey!\"]\n",
    "    else:\n",
    "        percent_hiked = round((distance / 6.87) * 100, 2)\n",
    "        label = [f\"Congratulations, you have read for a total of {distance} miles, \", \n",
    "                 f\"which is {percent_hiked}% of the total journey!\"]\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont\n",
    "\n",
    "def draw_label(camp_index, trail, acclimatization = False, distance = 0):\n",
    "    image = Image.open('everest_reading_journey.png')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    # Cut-off for when we should swap the label line from down to up.\n",
    "    midpoint_y = image.height/2\n",
    "    \n",
    "    color = \"red\"\n",
    "    thickness = 5\n",
    "\n",
    "    original_distance = distance\n",
    "\n",
    "    if acclimatization:\n",
    "        if distance <= 0:\n",
    "            print(\"Please provide a valid distance if using acclimatization.\")\n",
    "            return\n",
    "        \n",
    "        # Determine whether we're moving forward or not based on step\n",
    "        acclim_directions = [1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1]\n",
    "        acclim_distances = [1.62, 1.62, 1.62, 1.62, 3.36, 3.36, 3.36, 1.64, 1.64, 3.36, 3.36, 1.64, 0.8, 1.07]\n",
    "\n",
    "        if camp_index == len(trail):\n",
    "            # Pre-check if we've reached the end of the trail even with acclimatization to make things easier\n",
    "            net_distance = sum(acclim_distances)\n",
    "            camp_coordinates = trail[max(trail.keys())][0]\n",
    "        else:   \n",
    "            net_distance = 0\n",
    "\n",
    "            for i in range(len(acclim_distances)):\n",
    "                # Check if this is the final step\n",
    "                if distance < acclim_distances[i]:\n",
    "                    # If so, add/substract the remaining distance to our net distance\n",
    "                    net_distance += distance * acclim_directions[i]\n",
    "                    break\n",
    "                \n",
    "                # Remove distance and add/remove from net distance based on step direction\n",
    "                distance -= acclim_distances[i]\n",
    "                net_distance += acclim_distances[i] * acclim_directions[i]\n",
    "            \n",
    "            accumulated_distance = 0\n",
    "            # Trail distance is in units, parameter distance is in miles, so we convert\n",
    "            trail_length = 0\n",
    "            for data in trail.values():\n",
    "                _, length = data\n",
    "                trail_length += length\n",
    "            net_distance = net_distance * (trail_length / 6.87)\n",
    "            \n",
    "            for key, data in trail.items():\n",
    "                coordinates, length = data\n",
    "                accumulated_distance += length\n",
    "                if accumulated_distance >= net_distance:\n",
    "                    camp_coordinates = coordinates\n",
    "                    break\n",
    "        \n",
    "    else:\n",
    "        camp_coordinates = trail[camp_index][0]\n",
    "        \n",
    "    x,y = camp_coordinates\n",
    "\n",
    "    if y < midpoint_y:\n",
    "        # This means we're in the top-half of the image, so we angle the line down\n",
    "        x_new = x - 50\n",
    "        y_new = y + 50\n",
    "    else:\n",
    "        x_new = x - 50\n",
    "        y_new = y - 50\n",
    "    \n",
    "    draw.line([(x_new, y_new), (x, y)], fill = color, width = thickness, joint = 'curve')\n",
    "    draw.line([(x_new - 100, y_new), (x_new, y_new)], fill = color, width = thickness, joint = 'curve')\n",
    "\n",
    "    font_size = 16\n",
    "    font_color = \"black\"\n",
    "    font = ImageFont.truetype(\"Roboto-Regular.ttf\", font_size)\n",
    "\n",
    "    label = get_label_data(original_distance, acclimatization)\n",
    "    for line in label:\n",
    "        draw.text((50, y_new - 50), line, fill = font_color, font = font)\n",
    "        y_new += 25\n",
    "    image.show()\n",
    "    image.save('everest_reading_journey.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_journey_acclim(distance, trail):\n",
    "    # Distance for individual steps in acclimatization climb\n",
    "    acclim_distances = [1.62, 1.62, 1.62, 1.62, 3.36, 3.36, 3.36, 1.64, 1.64, 3.36, 3.36, 1.64, 0.8, 1.07]\n",
    "    # 0-3: up to C1, 4-6: up to C2, 7-11: up to C3, 12: up to C4, 13: up to Summit\n",
    "    \n",
    "    for i in range(len(acclim_distances)):\n",
    "        # Find the step in the climb based on the distance\n",
    "        if distance < sum(acclim_distances[:i+1]):\n",
    "            acclim_journey_step = i\n",
    "            break\n",
    "        else:\n",
    "            acclim_journey_step = 999\n",
    "\n",
    "    # Set the camp_index to the index of highest point reached in the trail\n",
    "    if acclim_journey_step < 4:\n",
    "        camp_index = 62\n",
    "    elif acclim_journey_step < 7:\n",
    "        camp_index = 83\n",
    "    elif acclim_journey_step < 12:\n",
    "        camp_index = 110\n",
    "    elif acclim_journey_step < 13:\n",
    "        camp_index = 145\n",
    "    else:\n",
    "        camp_index = len(trail)\n",
    "    \n",
    "    # Draw the hiking path up to the highest point\n",
    "    draw_trail(trail, camp_index)\n",
    "    draw_label(camp_index, trail, True, distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_journey_single(distance, trail):\n",
    "    accumulated_distance = 0\n",
    "    target_coordinates = None\n",
    "\n",
    "    # Trail distance is in units, parameter distance is in miles, so we convert\n",
    "    original_distance = distance\n",
    "    trail_length = 0\n",
    "    for data in trail.values():\n",
    "        _, length = data\n",
    "        trail_length += length\n",
    "    distance = distance * (trail_length / 6.87)\n",
    "\n",
    "    # If distance surpasses trail length, set index to max for summit\n",
    "    if distance >= trail_length:\n",
    "        camp_index = len(trail)\n",
    "    # Otherwise find index of nearest point on trail to our distance\n",
    "    else:\n",
    "        for key, data in trail.items():\n",
    "            coordinates, length = data\n",
    "            accumulated_distance += length\n",
    "            if accumulated_distance >= distance:\n",
    "                camp_index = key\n",
    "                break\n",
    "    \n",
    "    draw_trail(trail, camp_index)\n",
    "    draw_label(camp_index, trail, False, original_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_journey(distance, trail, acclimatization = False):\n",
    "    if acclimatization is not True:\n",
    "        plot_journey_single(distance, trail)\n",
    "    else:\n",
    "        plot_journey_acclim(distance, trail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so all of the functions are done. In total, we have:\n",
    "\n",
    "plot_journey -> This plots the entire journey based on the distance and the trail, and determines whether to use a single-trip setting or the acclimatization setting. It will call the corresponding function based on that parameter.\n",
    "\n",
    "plot_trail & plot_label -> These will plot the trail, up to the highest point for single journey, or the highest camp reached for acclimatization journies, and then also add a label at the end-point for each journey describing the percentage completed, etc.\n",
    "\n",
    "We have also used earlier functions to get our distance in books_distance, our trail data in trail, and any other stored data we may need in books_data. \n",
    "\n",
    "I also quickly edited the image and changed the filepath retroactively to point towards the new, cleaned-up version of Everest where all the campsites are marked on the right to make label-drawing more consistent on the left-side without worrying about overlaps.\n",
    "\n",
    "Let's see how it looks put together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.937736742424242\n"
     ]
    }
   ],
   "source": [
    "print(books_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_journey(books_distance, trail, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
